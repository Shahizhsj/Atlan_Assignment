{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8af0748b"
   },
   "source": [
    "## Feature 1 — Ticket Classification\n",
    "\n",
    "**What it does:**  \n",
    "Automatically classifies support tickets using an AI model.\n",
    "\n",
    "**How it works:**\n",
    "- Loads tickets from a JSON file.\n",
    "- Uses Google Generative AI to assign:\n",
    "  - **Topic** (e.g., Product, Feedback)\n",
    "  - **Sentiment** (e.g., Angry, Curious)\n",
    "  - **Priority** (P0, P1, P2)\n",
    "\n",
    "**Result:**  \n",
    "Each ticket gets these three labels for easier management.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "OnEK_sqqFQ5u",
    "outputId": "e4d6e3e0-737f-4d26-bc42-4c465f6622d9"
   },
   "outputs": [],
   "source": [
    "!pip install -U langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wyz94YDaPDvB",
    "outputId": "4867751c-f711-4668-8caf-6dde212a9e3b"
   },
   "outputs": [],
   "source": [
    "!pip install -q langchain-community langchain-core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_z3efuCvOZdj"
   },
   "source": [
    "### Defing our LLM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-6CA4vr5NgSI"
   },
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "GOOGLE_API_KEY=\"AIzaSyDiE4IX_azfFI7sbnYDUXAUl949lzFr8kg\"\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", google_api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8kOUz49OcIV"
   },
   "source": [
    "### Definig our System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "asqFiNigN-e6"
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "classification_prompt = PromptTemplate(\n",
    "    input_variables=[\"ticket_id\",\"ticker_subject\",\"ticket_text\"],\n",
    "    template=(\n",
    "        \"You are a ticket classification assistant.\\n\"\n",
    "        \"Given the user support ticket below, label it with:\\n\"\n",
    "        \"  - Topic: one of [How-to, Product, Connector, Feedback, ...]\\n\"\n",
    "        \"  - Sentiment: one of [Frustrated, Curious, Angry, Neutral]\\n\"\n",
    "        \"  - Priority: one of [P0/High, P1/Medium, P2/Low]\\n\"\n",
    "        \"Ticket Id: {ticket_id}\\n\"\n",
    "        \"Subject: {ticker_subject}\\n\"\n",
    "        \"Ticket:\\n---\\n{ticket_text}\\n---\\n\"\n",
    "        \"Return format:\\n\"\n",
    "        \"Topic: <topic>\\nSentiment: <sentiment>\\nPriority: <priority>\\n\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57RxjeCvGfg3"
   },
   "source": [
    "### Creating LLM Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GvU0bCC3OkP_",
    "outputId": "0bb80393-6b06-4d15-8423-006e06487f28"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "classification_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=classification_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2k0YxdNMGh1U"
   },
   "source": [
    "### Loading the Data from `tickets.json` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AT6Y2CkkP6O4",
    "outputId": "322895df-117c-479b-edc2-be4ce44bb3ff"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/content/tickets_data.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "ids = [ticket['id'] for ticket in data]\n",
    "subjects = [ticket['subject'] for ticket in data]\n",
    "bodies = [ticket['body'] for ticket in data]\n",
    "\n",
    "print(\"IDs:\", len(ids))\n",
    "print(\"Subjects:\", len(subjects))\n",
    "print(\"Bodies:\", len(bodies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZRvhs7pGl0A"
   },
   "source": [
    "### Passing each ticket to the LLM chain and store the results in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aOHbqzysU9GM",
    "outputId": "f57b3ba8-57c2-4ca5-a5bd-23ee845692df"
   },
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def classify_ticket(ticket_input):\n",
    "    return classification_chain.apply([ticket_input])[0][\"text\"]\n",
    "\n",
    "inputs = [\n",
    "    {\"ticket_id\": ids[i], \"ticker_subject\": subjects[i], \"ticket_text\": bodies[i]}\n",
    "    for i in range(len(ids))\n",
    "]\n",
    "\n",
    "results = []\n",
    "with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    futures = [executor.submit(classify_ticket, inp) for inp in inputs]\n",
    "    for future in as_completed(futures):\n",
    "        results.append(future.result())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "O9BdlR5gVotK",
    "outputId": "76483380-60f5-457e-db1e-4417c3020c0b"
   },
   "outputs": [],
   "source": [
    "results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "-nsS1rL8Wo_J",
    "outputId": "98bde360-9078-4a01-8e89-43afcd084d7b"
   },
   "outputs": [],
   "source": [
    "ids[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "lD8p4yUJWsp5",
    "outputId": "9556182d-1d83-410c-fbd3-440741ca5d14"
   },
   "outputs": [],
   "source": [
    "subjects[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "h0BHSX_hWtu1",
    "outputId": "ab04fad9-b0cf-4af6-a897-4d8e7ee92439"
   },
   "outputs": [],
   "source": [
    "bodies[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PjI8-JTy855u"
   },
   "source": [
    "## Feature 2 — Documentation Crawler & Retriever\n",
    "\n",
    "**What it does:**  \n",
    "Crawls Atlan documentation sites to collect pages, builds a searchable knowledge base, and enables question-answering over the docs.\n",
    "\n",
    "**How it works:**\n",
    "- Crawls all relevant pages from given documentation URLs.\n",
    "- Extracts and saves page text in chunks for processing.\n",
    "- Converts text into embeddings and stores them using FAISS for fast retrieval.\n",
    "- Provides a QA (Question Answering) interface powered by Google Generative AI, allowing users to ask questions and get answers based on the crawled documentation.\n",
    "\n",
    "**Result:**  \n",
    "You can search and answer queries from Atlan docs instantly using natural language, making it easy to find information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mH8MobZt7T6_",
    "outputId": "b42ec5e9-d05f-44e1-e812-2d30796e444c"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse\n",
    "START_URL = \"https://docs.atlan.com/\"\n",
    "visited = set()\n",
    "to_visit = [START_URL]\n",
    "all_urls_ = set()\n",
    "while to_visit:\n",
    "    url = to_visit.pop(0)\n",
    "    if url in visited or \".pdf\" in url or \"#\" in url:\n",
    "        continue\n",
    "    try:\n",
    "        resp = requests.get(url, timeout=10)\n",
    "        visited.add(url)\n",
    "        all_urls_.add(url)\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "        for link in soup.find_all(\"a\", href=True):\n",
    "            full_url = urljoin(url, link[\"href\"])\n",
    "            if urlparse(full_url).netloc == urlparse(START_URL).netloc and full_url not in visited:\n",
    "                to_visit.append(full_url)\n",
    "    except Exception as e:\n",
    "        print(f\"Error visiting {url}: {e}\")\n",
    "\n",
    "print(f\"Discovered {len(all_urls_)} documentation URLs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8BxFDZTEHJi_",
    "outputId": "e868258b-0229-48a3-d482-003d44fd3ede"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse\n",
    "START_URL = \"https://developer.atlan.com/\"\n",
    "visited = set()\n",
    "to_visit = [START_URL]\n",
    "all_urls= set()\n",
    "\n",
    "while to_visit:\n",
    "    url = to_visit.pop(0)\n",
    "    if url in visited or \".pdf\" in url or \"#\" in url:\n",
    "        continue\n",
    "    try:\n",
    "        resp = requests.get(url, timeout=10)\n",
    "        visited.add(url)\n",
    "        all_urls.add(url)\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "        for link in soup.find_all(\"a\", href=True):\n",
    "            full_url = urljoin(url, link[\"href\"])\n",
    "            if urlparse(full_url).netloc == urlparse(START_URL).netloc and full_url not in visited:\n",
    "                to_visit.append(full_url)\n",
    "    except Exception as e:\n",
    "        print(f\"Error visiting {url}: {e}\")\n",
    "print(f\"Discovered {len(all_urls)} documentation URLs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GBVfv5dlJpMU",
    "outputId": "34a3a099-d880-4c49-950f-e6d567f7d326"
   },
   "outputs": [],
   "source": [
    "all_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "43853de3",
    "outputId": "e5aa9a6b-9961-4524-dfaf-146011550143"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save all_urls to a JSON file\n",
    "with open(\"developer_atlan_urls.json\", \"w\") as f:\n",
    "    json.dump(list(all_urls), f)\n",
    "\n",
    "# Save all_urls_ to a JSON file\n",
    "with open(\"docs_atlan_urls.json\", \"w\") as f:\n",
    "    json.dump(list(all_urls_), f)\n",
    "\n",
    "print(\"URLs saved to developer_atlan_urls.json and docs_atlan_urls.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ru4ms2FVOUo",
    "outputId": "9cecdfee-c33b-4364-b3f6-309ca6da921d"
   },
   "outputs": [],
   "source": [
    "all_urls_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASJd6_kXJRf5"
   },
   "source": [
    "### Retrive the text from each link and store them in `Docunments` list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wws6_yGVVSwx"
   },
   "outputs": [],
   "source": [
    "def fetch_page_text(url):\n",
    "    resp = requests.get(url)\n",
    "    soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "    for tag in soup(['nav', 'footer', 'script', 'style']):\n",
    "        tag.decompose()\n",
    "    text = '\\n'.join([p.get_text(separator=' ', strip=True) for p in soup.find_all(['p', 'li', 'h2', 'h3'])])\n",
    "    return text\n",
    "\n",
    "def chunk_text(text, max_chunk_size=500):\n",
    "    words = text.split()\n",
    "    return [' '.join(words[i:i+max_chunk_size]) for i in range(0, len(words), max_chunk_size)]\n",
    "documents = []\n",
    "for url in all_urls_:\n",
    "    raw_text = fetch_page_text(url)\n",
    "    for chunk in chunk_text(raw_text):\n",
    "        documents.append({\"text\": chunk, \"source\": url})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b65hNkbMVioU"
   },
   "outputs": [],
   "source": [
    "def fetch_page_text(url):\n",
    "    resp = requests.get(url)\n",
    "    soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "    for tag in soup(['nav', 'footer', 'script', 'style']):\n",
    "        tag.decompose()\n",
    "    text = '\\n'.join([p.get_text(separator=' ', strip=True) for p in soup.find_all(['p', 'li', 'h2', 'h3'])])\n",
    "    return text\n",
    "\n",
    "def chunk_text(text, max_chunk_size=500):\n",
    "    words = text.split()\n",
    "    return [' '.join(words[i:i+max_chunk_size]) for i in range(0, len(words), max_chunk_size)]\n",
    "\n",
    "for url in all_urls:\n",
    "    raw_text = fetch_page_text(url)\n",
    "    for chunk in chunk_text(raw_text):\n",
    "        documents.append({\"text\": chunk, \"source\": url})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nVzr6pJvXMy7",
    "outputId": "4804ea4a-48ed-495d-8c85-4b04a50fd7cb"
   },
   "outputs": [],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wYoKhTFCbi3o",
    "outputId": "1ee5916a-4045-4b9a-a3c9-071c81b461ae"
   },
   "outputs": [],
   "source": [
    "!pip install -q faiss-cpu chromadb langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SxgWmyelyRsN",
    "outputId": "63e1dfbe-de59-42ea-f4ab-cf2d51bc65f5"
   },
   "outputs": [],
   "source": [
    "!pip install -q langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0xm4pfJIo2rN"
   },
   "outputs": [],
   "source": [
    "texts = [doc[\"text\"] for doc in documents]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6nYXgXxSsYVM"
   },
   "outputs": [],
   "source": [
    "metadatas = [{\"source\": doc[\"source\"]} for doc in documents]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369,
     "referenced_widgets": [
      "cfccbd0ccc9e4a34b91059a8d1049efb",
      "50a09e335f134c19aba195f544c4cf6d",
      "f4e7fd028764436788b8d22cc530e67e",
      "f0b30b076485488db200c8db53a8ebe6",
      "84886a7844074ee8aa4fec256ab44f91",
      "4f22f8cce07a4627b297ed75f4a3e5ea",
      "cea4a92320464931a189790c54c1bae4",
      "73b17566cc6748f1b2d104ad67815bd2",
      "424d3c82ef8b4869a1788f606717d322",
      "9789e561e4444f2eaed3b145403182a8",
      "bbf365cb134c41279c2693bb7559719e",
      "234bef5b352445aa81b77408c03c86e7",
      "33e07d3b1a47414b8ecffc4f53d3a650",
      "6d44d2dcf5bb452a933c80d212043d7c",
      "cf59c7ca3236467cbd9d95917537469d",
      "51a67b14b3c64a18acf56a0c7a1775b2",
      "b3111e6b14824bf195a85cde20f0487c",
      "9e2d2c0bec6b459e81f6ddb990f0898a",
      "74b50fd134a046a59cb9120c623a9806",
      "c96f029d2fef40fd8faf3c0aa9255c67",
      "bc0a984de57e4c29b0333921dc344ff8",
      "05d1f0f330284f98b3b489a6c8855c4d",
      "c84a7effa0ce4652b75a8fc171c531cc",
      "20c561797aa949ff91324bee9578c4a6",
      "e1bd45300f034e13a50e4395714c2cbf",
      "f82efc6813094b07af637579af5117ea",
      "01ca584acdde4aa5a420e1f9a4b35a88",
      "c8b1f96f2c7c4eccb3ff3d7f624c3254",
      "8013098d72fd4a7f80bde4001f5308b8",
      "3b8aef0c30a3487b9dce5b5608ab503f",
      "668a226d99ae42aca909e6467253c30b",
      "7093763cec1b4d4da2c9656a552c990c",
      "d4bb3728c26d4c4dbae54d2a5c2ccf6b",
      "047a0e228f6c4e8fa8864d17b1a30e55",
      "4165f2dac6444edebe7c09bb29343ee7",
      "4cfe81a7b9524e7db7d3c8cca7a6ec69",
      "6bb1853e9f0d45f48bb1fa3ec52182b0",
      "1dc6f12fcc00430199a16167e022b59f",
      "1040c77eab4b4d85943b4f9d4b4fdf3b",
      "aed8148fe9b04a658a115245a7f915a6",
      "961e5f01afb346298957b178ef30cd89",
      "6e278be0561849cba8c329d50225d058",
      "f6fc4ae77aac4c4eadba9ce0fdb5fdff",
      "2e22402e198e4ecfaf75d2989b833407",
      "1a1f11e22bed47ea9c7801edd58a9940",
      "d938aaae8fbc4908a41c25b70236440f",
      "394c5c2b9fc343c8a7dd28d4e6d6a0eb",
      "031cae83d16e4db39bc8d8bc2fb8fc84",
      "676b17b342d741ce91d7918638fa55aa",
      "050ee38e19c640d1a20a95091d95b04f",
      "35e01e6bbbce425ca9c9cb841570d9c4",
      "ef4959178e0c45ca9316f7703fc4b2c1",
      "ec0e74f4d9fa426a9e34890a34dff8b1",
      "226ba96a76f64f67b008c25be6ef5534",
      "d21d7248bb9f425fb99f8e73e0c47950",
      "4fb6bcc0f3ef44e98ee02673271c812d",
      "f92621ef208a45ab8fd31d15e3c6f4ce",
      "c48d2e40715e4f3f85a0caf7bd92c171",
      "95bc0316320441ddbcfc4c1c4b40745d",
      "12ed8e2338c343b3947ebe9724ea7c1a",
      "a4a27d5b5e14485da775902bc5d21e7b",
      "96cf5096a9aa429d933ec6575197424c",
      "4fec03ac81a74b2d94f0e5ca42c3a94a",
      "7a27046133c94caaa227dc932a4c94f2",
      "818e5a5eb6e240c78fcc38090837d62a",
      "440596f6b7424804b05bd6bdcd2b3714",
      "db4fbe3039ca4a348992a220cc0ff654",
      "ec9189fc5b3547bbb9cf94af7281a44e",
      "b1cc90347e414a789cecff69a1577ff6",
      "0ed16a3e0c7f452db324189ec6dbe9e5",
      "47ce4c1d04a742209f1e8c4a505de669",
      "630a1f0b8b754635af598850e827cd21",
      "c496f5e7a8de474794d615f0dd3d359a",
      "076699eac8fd4d80911c332c4e036c35",
      "04d68bacc51b423f93494e7a41105c20",
      "6ec1208c5f1a4804968273b77b59b326",
      "4e557f882c954c99ae132a2a3b0edd04",
      "db95cedd236b411faab1483649732bc7",
      "94d376b0328649b2bec3971cc66327a8",
      "40b3a3a3ae444b51b0bcf08ffe75ce4d",
      "aee54999fd8a4d7b878a3efa6a0e3674",
      "ddd7bf5cb9804ad98217fb5503df26e1",
      "4a90f3fb017e4145a964d656f8f220ee",
      "2fabb338191e48a29d38ab4d03242e89",
      "a04ce2bb6a834d8f9a420caf33adc845",
      "8dc22e126e5b4751b1d92095bddc02b2",
      "49197dad71dd4881b348ff21e83b72c1",
      "6678ddb51d4642e3b221eb2a635e5752",
      "0137a78a64cb4780a81847902413fbaa",
      "b5bff39f414142d9a30c591d32f4eed1",
      "81ae351aa698439986318b5ee07b7337",
      "269fbc5d6c48438ab4d15332f98f72b4",
      "75530ed0326a47aaa190d9456cfacc82",
      "57d9e6d90893474588b644078d89c1b5",
      "a37c42ac95044bea8b7da0e4acc9a999",
      "f745a57c67ab45bd82ad4cf372bf3417",
      "c982895e17484383b87e42c58c208525",
      "d391cbaf1d1c4f928ab3398c58d84f79",
      "a354258ebb354f7db18ce619cd2d5b0c",
      "054da81fdbff4e32a992f2c3e9b998c5",
      "b9c81cdedc4943c38101ec83e794ac21",
      "5ae3e43ac61f40febba5187812c9f30e",
      "640fde499a0441008da625648b783a84",
      "147af95b9b954acfa37a1c28cf85450b",
      "3096fde212a745ca821645c3dde4ea95",
      "c483c0ea493b4cccb9173a6233ff2698",
      "a1b0f3c592ef48e98776aec5f74a561e",
      "1527ba70c2934e2cbc782d0e64bb16eb",
      "7d4dafa339584d0198b588d7f4d3f2ed",
      "9dbaed912ddd48b292e7a227fa116386",
      "16d468381a4d498283a60d787bb4eb88",
      "99efff39712740f5b4726308d6b16082",
      "3ffdd429afe84c1385dc0d53bebbbeae",
      "2aac73d2075847fea9002f80b88d0ae2",
      "491a233da5904956905c96f273812499",
      "fc4192a944614b75ac8a09ccbd93c311",
      "19fedc8d7b2e41c395afdaad8a746514",
      "c437ac9f7c3b4345a44de02187821f74",
      "9d9e037d1f384e6ab03bde37a37ab883",
      "f50c6687ca1a42baa2921891284c035a",
      "bcfbc870b72040e6994e977774be3554"
     ]
    },
    "id": "DnlT7aPZZTFn",
    "outputId": "f8365a71-c0c4-4e9d-8153-6f57ffc4861c"
   },
   "outputs": [],
   "source": [
    "!pip install -q sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wb-YMToJrB4q"
   },
   "outputs": [],
   "source": [
    "import faiss\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LwUBMaeWmEBf"
   },
   "outputs": [],
   "source": [
    "faiss.write_index(index, \"faiss.index\")\n",
    "import json\n",
    "with open(\"metadata.json\", \"w\") as f:\n",
    "    json.dump(documents, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H61hIYGPB7v2",
    "outputId": "4932ae01-1253-4ff7-fd36-dbf70b352e1c"
   },
   "outputs": [],
   "source": [
    "!pip install -q -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GO1Rb6klsG7u",
    "outputId": "66a5804b-c01a-454c-a70d-90747ac540b3"
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vectorstore = FAISS.from_texts(texts, embedding=embeddings, metadatas=metadatas)\n",
    "vectorstore.save_local(\"faiss_store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8yoQ4Fjrvb2C"
   },
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vectorstore = FAISS.load_local(\"faiss_store\", embeddings,allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wlNzo9RGvckH"
   },
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a7HYNnwivz8t"
   },
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"Context:\\n{context}\\n\\nQuestion: {question}\\n\\nAnswer:\",\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D323cI4TJi1y"
   },
   "source": [
    "### We create the `qa_chain`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VWUhvCIBvrPm"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": prompt},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-Fo0p3DJnvE"
   },
   "source": [
    "### Testing by passing an query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iuBD7zKUv1nq",
    "outputId": "63664f49-5ab5-479d-e7e9-85781d47cffb"
   },
   "outputs": [],
   "source": [
    "query = \"Hi team, we're trying to set up our primary Snowflake production database as a new source in Atlan, but the connection keeps failing. We've tried using our standard service account, but it's not working. Our entire BI team is blocked on this integration for a major upcoming project, so it's quite urgent. Could you please provide a definitive list of the exact permissions and credentials needed on the Snowflake side to get this working? Thanks.\"\n",
    "result = qa_chain({\"query\": query})\n",
    "print(\"Answer:\", result[\"result\"])\n",
    "\n",
    "if \"source_documents\" in result:\n",
    "    print(\"\\nSources:\")\n",
    "    for doc in result[\"source_documents\"]:\n",
    "        url = doc.metadata.get(\"source\", None) or doc.metadata.get(\"url\", None)\n",
    "        print(f\"- {url}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OGOxPpiazuqt"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
